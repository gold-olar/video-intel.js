/**
 * FrameAnalyzer - Abstract base class for video frame analysis
 * 
 * This class provides a common foundation for all frame-based analysis operations
 * in VideoIntel.js. It includes utility methods for extracting image data, calculating
 * statistics, and managing cache and performance metrics.
 * 
 * Key features:
 * - Abstract analyze() method that subclasses must implement
 * - Common statistical calculations (brightness, contrast, sharpness, etc.)
 * - Frame quality checks (black, white, blur detection)
 * - Optional caching for improved performance
 * - Optional performance tracking for optimization
 * 
 * Usage:
 * Extend this class and implement the analyze() method with your specific logic.
 * 
 * @example
 * ```typescript
 * class ThumbnailScorer extends FrameAnalyzer<ScoredFrame> {
 *   async analyze(frame: HTMLCanvasElement): Promise<ScoredFrame> {
 *     const stats = this.calculateStatistics(this.extractImageData(frame));
 *     return { score: stats.brightness * stats.sharpness, stats };
 *   }
 * }
 * ```
 * 
 * @module core/FrameAnalyzer
 */

import { VideoIntelError, ErrorCode } from '../types';
import type {
  FrameAnalysisResult,
  FrameStatistics,
  FrameAnalyzerOptions,
  AnalysisPerformance,
  FrameQualityThresholds,
  // FrameAnalyzerErrorCode
} from '../types/analyzer';

/**
 * Default thresholds for frame quality detection.
 * These values work well for most use cases but can be adjusted based on your needs.
 */
const DEFAULT_THRESHOLDS: FrameQualityThresholds = {
  blackFrameThreshold: 0.1,   // Frames with <10% brightness are considered black
  whiteFrameThreshold: 0.9,   // Frames with >90% brightness are considered white
  blurThreshold: 0.3          // Frames with <30% sharpness are considered blurry
};

/**
 * Abstract base class for frame analysis operations.
 * 
 * This class uses TypeScript generics to allow subclasses to define their own
 * result types while ensuring type safety across the codebase.
 * 
 * @template T - The type of analysis result, must extend FrameAnalysisResult
 */
export abstract class FrameAnalyzer<T extends FrameAnalysisResult> {
  /**
   * Cache for storing analysis results.
   * Key: string (generated by getCacheKey)
   * Value: T (the analysis result)
   * 
   * IMPROVEMENT: Could implement LRU cache or use a library like 'lru-cache'
   * for more sophisticated caching strategies.
   */
  protected cache: Map<string, T>;

  /** Configuration options for this analyzer */
  protected options: FrameAnalyzerOptions;

  /**
   * Array of performance metrics for tracking operation times.
   * 
   * IMPROVEMENT: Could add memory usage tracking or export metrics
   * to external monitoring systems.
   */
  protected performanceMetrics: AnalysisPerformance[];

  /** Quality thresholds for frame detection */
  protected thresholds: FrameQualityThresholds;

  /**
   * Counter for cache hits (for debugging/monitoring).
   * IMPROVEMENT: Could expose this via a public getter for monitoring.
   */
  private cacheHits: number = 0;

  /**
   * Counter for cache misses (for debugging/monitoring).
   * IMPROVEMENT: Could expose this via a public getter for monitoring.
   */
  private cacheMisses: number = 0;

  /**
   * Creates a new FrameAnalyzer instance.
   * 
   * @param options - Configuration options for the analyzer
   * @param thresholds - Custom quality thresholds (optional)
   */
  constructor(
    options: FrameAnalyzerOptions = {},
    thresholds: Partial<FrameQualityThresholds> = {}
  ) {
    // Set default options
    this.options = {
      cache: options.cache ?? false,
      skipValidation: options.skipValidation ?? false,
      trackPerformance: options.trackPerformance ?? false,
      maxCacheSize: options.maxCacheSize ?? 100,
      analysisScale: options.analysisScale ?? 1.0
    };

    // Merge provided thresholds with defaults
    this.thresholds = {
      ...DEFAULT_THRESHOLDS,
      ...thresholds
    };

    // Initialize cache and metrics
    this.cache = new Map();
    this.performanceMetrics = [];
  }

  /**
   * Abstract method that subclasses must implement.
   * This is where the actual frame analysis logic goes.
   * 
   * @param frame - The canvas element containing the video frame
   * @param timestamp - Optional timestamp of the frame in the video (seconds)
   * @returns Promise resolving to the analysis result
   * 
   * @example
   * ```typescript
   * async analyze(frame: HTMLCanvasElement): Promise<MyResult> {
   *   const imageData = this.extractImageData(frame);
   *   const stats = this.calculateStatistics(imageData);
   *   return { score: stats.brightness, metadata: { stats } };
   * }
   * ```
   */
  abstract analyze(frame: HTMLCanvasElement, timestamp?: number): Promise<T>;

  // ============================================================================
  // IMAGE DATA EXTRACTION
  // ============================================================================

  /**
   * Extracts ImageData from a canvas element.
   * This is the first step in most frame analysis operations.
   * 
   * @param canvas - The canvas element to extract data from
   * @returns ImageData object containing pixel information
   * @throws VideoIntelError if extraction fails
   * 
   * IMPROVEMENT: Could add support for extracting only a region of the canvas
   * to analyze specific areas (e.g., center-weighted analysis).
   */
  protected extractImageData(canvas: HTMLCanvasElement): ImageData {
    // Start performance tracking if enabled
    const startTime = this.options.trackPerformance ? performance.now() : 0;

    try {
      // Get 2D rendering context
      const ctx = canvas.getContext('2d');
      if (!ctx) {
        throw new VideoIntelError(
          'Failed to get 2D context from canvas',
          ErrorCode.PROCESSING_ERROR
        );
      }

      // Apply scaling if needed (for performance optimization)
      const scale = this.options.analysisScale ?? 1.0;
      const width = Math.floor(canvas.width * scale);
      const height = Math.floor(canvas.height * scale);

      // Extract image data
      // Note: getImageData can be expensive for large canvases
      const imageData = ctx.getImageData(0, 0, width, height);

      // Track performance
      if (this.options.trackPerformance) {
        this.endTracking(startTime, 'extractImageData', width * height);
      }

      return imageData;
    } catch (error) {
      throw new VideoIntelError(
        `Failed to extract image data: ${error instanceof Error ? error.message : 'Unknown error'}`,
        ErrorCode.PROCESSING_ERROR,
        error
      );
    }
  }

  // ============================================================================
  // FRAME VALIDATION
  // ============================================================================

  /**
   * Validates that a canvas element is suitable for analysis.
   * Performs several checks to ensure the frame can be processed safely.
   * 
   * @param canvas - The canvas element to validate
   * @returns true if valid, false otherwise
   * 
   * IMPROVEMENT: Could add more sophisticated checks like:
   * - Check for corrupted image data
   * - Detect completely transparent frames
   * - Validate aspect ratio ranges
   */
  protected validateFrame(canvas: HTMLCanvasElement): boolean {
    // Check if canvas exists
    if (!canvas) {
      return false;
    }

    // Check if canvas has valid dimensions
    if (canvas.width <= 0 || canvas.height <= 0) {
      return false;
    }

    // Check if we can get a context (indicates valid canvas)
    const ctx = canvas.getContext('2d');
    if (!ctx) {
      return false;
    }

    // All checks passed
    return true;
  }

  // ============================================================================
  // STATISTICAL CALCULATIONS
  // ============================================================================

  /**
   * Calculates comprehensive statistics for a frame.
   * This is optimized to compute all statistics in a single pass through the pixel data.
   * 
   * @param imageData - The image data to analyze
   * @returns FrameStatistics object with all calculated metrics
   * 
   * Performance note: This method processes every pixel, so it can be expensive
   * for high-resolution frames. Consider using analysisScale option for large frames.
   * 
   * IMPROVEMENT: Could use Web Workers for parallel processing of large frames
   * IMPROVEMENT: Could add more statistics like saturation, hue distribution, etc.
   */
  protected calculateStatistics(imageData: ImageData): FrameStatistics {
    const startTime = this.options.trackPerformance ? performance.now() : 0;

    // Calculate all basic statistics
    const brightness = this.calculateBrightness(imageData);
    const contrast = this.calculateContrast(imageData);
    const sharpness = this.calculateSharpness(imageData);
    const colorVariance = this.calculateColorVariance(imageData);

    // Perform quality checks using calculated statistics
    const isBlackFrame = brightness < this.thresholds.blackFrameThreshold;
    const isWhiteFrame = brightness > this.thresholds.whiteFrameThreshold;
    const isBlurry = sharpness < this.thresholds.blurThreshold;

    if (this.options.trackPerformance) {
      this.endTracking(
        startTime,
        'calculateStatistics',
        imageData.width * imageData.height
      );
    }

    return {
      brightness,
      contrast,
      sharpness,
      colorVariance,
      isBlackFrame,
      isWhiteFrame,
      isBlurry
    };
  }

  /**
   * Calculates the average brightness of a frame.
   * Uses the standard luminance formula that weights colors based on human perception.
   * 
   * Formula: Y = 0.299R + 0.587G + 0.114B
   * (Green contributes most to perceived brightness, blue contributes least)
   * 
   * @param imageData - The image data to analyze
   * @returns Brightness value normalized to 0-1 range
   * 
   * IMPROVEMENT: Could calculate brightness histogram for more detailed analysis
   */
  protected calculateBrightness(imageData: ImageData): number {
    const { data } = imageData;
    let sum = 0;

    // Process every pixel
    // ImageData format: [R, G, B, A, R, G, B, A, ...]
    for (let i = 0; i < data.length; i += 4) {
      const r = data[i];     // Red channel
      const g = data[i + 1]; // Green channel
      const b = data[i + 2]; // Blue channel
      // Skip alpha channel (data[i + 3])

      // Calculate luminance using standard formula
      const luminance = 0.299 * r + 0.587 * g + 0.114 * b;
      sum += luminance;
    }

    // Calculate average and normalize to 0-1 range
    const pixelCount = data.length / 4;
    const average = sum / pixelCount;
    return average / 255; // Normalize from 0-255 to 0-1
  }

  /**
   * Calculates the contrast level of a frame.
   * Contrast is measured as the difference between the brightest and darkest pixels.
   * 
   * High contrast images have a wide range of brightness values.
   * Low contrast images appear flat or washed out.
   * 
   * @param imageData - The image data to analyze
   * @returns Contrast value normalized to 0-1 range
   * 
   * IMPROVEMENT: Could use RMS (Root Mean Square) contrast for more accurate results
   * IMPROVEMENT: Could implement Michelson contrast or Weber contrast methods
   */
  protected calculateContrast(imageData: ImageData): number {
    const { data } = imageData;
    let min = 255; // Start with maximum possible value
    let max = 0;   // Start with minimum possible value

    // Find min and max luminance values
    for (let i = 0; i < data.length; i += 4) {
      const r = data[i];
      const g = data[i + 1];
      const b = data[i + 2];

      // Calculate luminance
      const luminance = 0.299 * r + 0.587 * g + 0.114 * b;

      // Update min and max
      if (luminance < min) min = luminance;
      if (luminance > max) max = luminance;
    }

    // Calculate contrast as the range of luminance values
    const contrast = max - min;
    return contrast / 255; // Normalize to 0-1
  }

  /**
   * Calculates the sharpness of a frame using Laplacian variance.
   * Sharpness indicates how in-focus an image is.
   * 
   * The Laplacian operator detects edges by computing second derivatives.
   * Sharp images have strong edges and high variance, blurry images have low variance.
   * 
   * Laplacian kernel used:
   *   [ 0 -1  0]
   *   [-1  4 -1]
   *   [ 0 -1  0]
   * 
   * @param imageData - The image data to analyze
   * @returns Sharpness value normalized to 0-1 range
   * 
   * Performance note: This is the most expensive calculation as it processes
   * neighboring pixels. Consider downsampling for very large images.
   * 
   * IMPROVEMENT: Could use FFT (Fast Fourier Transform) for frequency-based sharpness
   * IMPROVEMENT: Could implement Sobel operator for edge detection
   * IMPROVEMENT: Could add directional sharpness (horizontal vs vertical edges)
   */
  protected calculateSharpness(imageData: ImageData): number {
    const { data, width, height } = imageData;
    let sum = 0;
    let count = 0;

    // We need to skip the border pixels since they don't have all neighbors
    // This is a simplified Laplacian operator implementation
    for (let y = 1; y < height - 1; y++) {
      for (let x = 1; x < width - 1; x++) {
        // Calculate index of current pixel (using red channel only for simplicity)
        const idx = (y * width + x) * 4;

        // Get current pixel and its neighbors
        const center = data[idx];
        const left = data[idx - 4];
        const right = data[idx + 4];
        const top = data[idx - width * 4];
        const bottom = data[idx + width * 4];

        // Apply Laplacian kernel: 4*center - left - right - top - bottom
        const laplacian = Math.abs(
          4 * center - left - right - top - bottom
        );

        sum += laplacian;
        count++;
      }
    }

    // Calculate average (variance of Laplacian)
    const variance = count > 0 ? sum / count : 0;

    // Normalize to 0-1 range
    // Note: 100 is an empirical value that works well for most images
    // IMPROVEMENT: This normalization could be calibrated more precisely
    return Math.min(1, variance / 100);
  }

  /**
   * Calculates the color variance (diversity) of a frame.
   * High variance means the image has diverse colors.
   * Low variance means the image is mostly monochrome or has limited colors.
   * 
   * This is useful for filtering boring/monochrome frames when selecting thumbnails.
   * 
   * @param imageData - The image data to analyze
   * @returns Color variance normalized to 0-1 range
   * 
   * IMPROVEMENT: Could calculate variance in HSV/HSL space for better color perception
   * IMPROVEMENT: Could weight variance by color importance (e.g., skin tones)
   * IMPROVEMENT: Could calculate per-channel variance for more detailed analysis
   */
  protected calculateColorVariance(imageData: ImageData): number {
    const { data } = imageData;
    const pixelCount = data.length / 4;

    // First pass: Calculate mean RGB values
    let sumR = 0, sumG = 0, sumB = 0;
    for (let i = 0; i < data.length; i += 4) {
      sumR += data[i];
      sumG += data[i + 1];
      sumB += data[i + 2];
    }

    const meanR = sumR / pixelCount;
    const meanG = sumG / pixelCount;
    const meanB = sumB / pixelCount;

    // Second pass: Calculate variance
    let varianceSum = 0;
    for (let i = 0; i < data.length; i += 4) {
      // Calculate squared differences from mean for each channel
      const diffR = data[i] - meanR;
      const diffG = data[i + 1] - meanG;
      const diffB = data[i + 2] - meanB;

      // Sum of squared differences
      varianceSum += diffR * diffR + diffG * diffG + diffB * diffB;
    }

    // Calculate average variance across all channels
    const variance = varianceSum / (pixelCount * 3);

    // Normalize to 0-1 range
    // Note: 10000 is an empirical value that works well for most images
    // IMPROVEMENT: This normalization could be calibrated more precisely
    return Math.min(1, variance / 10000);
  }

  // ============================================================================
  // FRAME QUALITY CHECKS
  // ============================================================================

  /**
   * Checks if a frame is predominantly black.
   * Useful for filtering out fade-to-black transitions or invalid frames.
   * 
   * @param imageData - The image data to check
   * @param customThreshold - Optional custom threshold (overrides default)
   * @returns true if frame is black, false otherwise
   */
  protected isBlackFrame(
    imageData: ImageData,
    customThreshold?: number
  ): boolean {
    const threshold = customThreshold ?? this.thresholds.blackFrameThreshold;
    const brightness = this.calculateBrightness(imageData);
    return brightness < threshold;
  }

  /**
   * Checks if a frame is predominantly white or overexposed.
   * Useful for filtering out fade-to-white transitions or overexposed frames.
   * 
   * @param imageData - The image data to check
   * @param customThreshold - Optional custom threshold (overrides default)
   * @returns true if frame is white, false otherwise
   */
  protected isWhiteFrame(
    imageData: ImageData,
    customThreshold?: number
  ): boolean {
    const threshold = customThreshold ?? this.thresholds.whiteFrameThreshold;
    const brightness = this.calculateBrightness(imageData);
    return brightness > threshold;
  }

  /**
   * Checks if a frame is blurry or out of focus.
   * Useful for filtering out low-quality frames when selecting thumbnails.
   * 
   * @param sharpness - Pre-calculated sharpness value (0-1)
   * @param customThreshold - Optional custom threshold (overrides default)
   * @returns true if frame is blurry, false otherwise
   * 
   * Note: Accepts pre-calculated sharpness to avoid redundant computation
   */
  protected isBlurryFrame(
    sharpness: number,
    customThreshold?: number
  ): boolean {
    const threshold = customThreshold ?? this.thresholds.blurThreshold;
    return sharpness < threshold;
  }

  // ============================================================================
  // CACHING SYSTEM
  // ============================================================================

  /**
   * Generates a cache key for a canvas.
   * The key should uniquely identify the frame to avoid cache collisions.
   * 
   * Current implementation uses dimensions and data URL.
   * 
   * @param canvas - The canvas to generate a key for
   * @returns A string key for caching
   * 
   * IMPROVEMENT: This could be optimized using a faster hashing algorithm
   * IMPROVEMENT: Could use image fingerprinting techniques for better uniqueness
   * IMPROVEMENT: Could include timestamp in key for time-based caching
   */
  protected getCacheKey(canvas: HTMLCanvasElement): string {
    // Simple key based on dimensions and data URL
    // Note: toDataURL() can be slow for large canvases
    // IMPROVEMENT: Could use a faster hash function on pixel data sample
    try {
      const dataURL = canvas.toDataURL('image/jpeg', 0.1); // Low quality for speed
      return `${canvas.width}x${canvas.height}_${dataURL.substring(0, 50)}`;
    } catch {
      // Fallback if toDataURL fails (e.g., tainted canvas)
      return `${canvas.width}x${canvas.height}_${Date.now()}`;
    }
  }

  /**
   * Retrieves a result from the cache.
   * 
   * @param key - The cache key to look up
   * @returns The cached result or undefined if not found
   */
  protected getFromCache(key: string): T | undefined {
    const result = this.cache.get(key);
    if (result) {
      this.cacheHits++;
    } else {
      this.cacheMisses++;
    }
    return result;
  }

  /**
   * Adds a result to the cache.
   * Implements simple size-based eviction when max size is reached.
   * 
   * @param key - The cache key
   * @param result - The result to cache
   * 
   * IMPROVEMENT: Should implement LRU (Least Recently Used) eviction
   * IMPROVEMENT: Could add time-based expiration
   * IMPROVEMENT: Could estimate memory usage and limit by memory instead of count
   */
  protected addToCache(key: string, result: T): void {
    // Check if we need to evict old entries
    if (this.cache.size >= (this.options.maxCacheSize ?? 100)) {
      // Simple eviction: remove the first (oldest) entry
      // IMPROVEMENT: Should use LRU policy instead
      const firstKey = this.cache.keys().next().value;
      if (firstKey) {
        this.cache.delete(firstKey);
      }
    }

    this.cache.set(key, result);
  }

  /**
   * Clears all cached results.
   * Useful for freeing memory after batch processing.
   */
  protected clearCache(): void {
    this.cache.clear();
    this.cacheHits = 0;
    this.cacheMisses = 0;
  }

  /**
   * Gets cache statistics for monitoring.
   * 
   * @returns Object with cache hit/miss counts and hit rate
   * 
   * IMPROVEMENT: Could be exposed as a public method for monitoring
   */
  protected getCacheStats() {
    const total = this.cacheHits + this.cacheMisses;
    const hitRate = total > 0 ? this.cacheHits / total : 0;

    return {
      hits: this.cacheHits,
      misses: this.cacheMisses,
      size: this.cache.size,
      hitRate: Math.round(hitRate * 100) / 100 // Round to 2 decimal places
    };
  }

  // ============================================================================
  // PERFORMANCE TRACKING
  // ============================================================================

  /**
   * Starts tracking a performance operation.
   * 
   * @returns The start timestamp
   */
  protected startTracking(): number {
    return performance.now();
  }

  /**
   * Ends tracking and records the performance metric.
   * 
   * @param startTime - The start timestamp from startTracking()
   * @param operation - Name/identifier of the operation
   * @param operationsCount - Optional count of operations performed (e.g., pixel count)
   */
  protected endTracking(
    startTime: number,
    operation: string,
    operationsCount?: number
  ): void {
    if (!this.options.trackPerformance) {
      return;
    }

    const endTime = performance.now();
    const duration = endTime - startTime;

    this.performanceMetrics.push({
      operation,
      startTime,
      endTime,
      duration,
      operationsCount
    });
  }

  /**
   * Gets all recorded performance metrics.
   * 
   * @returns Array of performance metrics
   * 
   * IMPROVEMENT: Could add methods to analyze metrics (average, min, max, etc.)
   * IMPROVEMENT: Could export metrics in various formats (JSON, CSV, etc.)
   */
  protected getPerformanceMetrics(): AnalysisPerformance[] {
    return [...this.performanceMetrics];
  }

  /**
   * Clears all performance metrics.
   * Useful for resetting between analysis sessions.
   */
  protected clearPerformanceMetrics(): void {
    this.performanceMetrics = [];
  }

  /**
   * Gets a summary of performance metrics.
   * Calculates average, min, and max durations across all operations.
   * 
   * @returns Performance summary statistics
   * 
   * IMPROVEMENT: Could group by operation type for more detailed analysis
   */
  protected getPerformanceSummary() {
    if (this.performanceMetrics.length === 0) {
      return {
        count: 0,
        totalDuration: 0,
        averageDuration: 0,
        minDuration: 0,
        maxDuration: 0
      };
    }

    const durations = this.performanceMetrics.map(m => m.duration);
    const totalDuration = durations.reduce((sum, d) => sum + d, 0);

    return {
      count: this.performanceMetrics.length,
      totalDuration: Math.round(totalDuration * 100) / 100,
      averageDuration: Math.round((totalDuration / durations.length) * 100) / 100,
      minDuration: Math.round(Math.min(...durations) * 100) / 100,
      maxDuration: Math.round(Math.max(...durations) * 100) / 100
    };
  }
}

